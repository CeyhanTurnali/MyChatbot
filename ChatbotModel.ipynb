{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Admin/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import string\n",
    "import re\n",
    "import joblib\n",
    "import json\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dense, Flatten\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadJson(jsonFile):\n",
    "    with open(jsonFile) as file:\n",
    "        JsonData = json.loads(file.read())\n",
    "    return JsonData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=loadJson(\"intent.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pullData(feat_1,feat_2,is_pattern):\n",
    "    is_pattern = is_pattern\n",
    "    df = pd.DataFrame(columns=[feat_1,feat_2])\n",
    "    for intent in data['intents']:\n",
    "        if is_pattern:\n",
    "            for pattern in intent['text']:\n",
    "                w = pattern\n",
    "                df_to_append = pd.Series([w,intent['intent']], index = df.columns)\n",
    "                df = df.append(df_to_append,ignore_index=True)\n",
    "        else:\n",
    "            for response in intent['responses']:\n",
    "                w = response\n",
    "                df_to_append = pd.Series([w,intent['intent']], index = df.columns)\n",
    "                df = df.append(df_to_append,ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = []\n",
    "for intent in data['intents']:\n",
    "    for pattern in intent['text']:\n",
    "        #tokenize each word\n",
    "        if intent['intent'] not in classes:\n",
    "            classes.append(intent['intent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['classes.pkl']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = sorted(list(set(classes)))\n",
    "joblib.dump(classes,'classes.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi</td>\n",
       "      <td>Greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hi there</td>\n",
       "      <td>Greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hola</td>\n",
       "      <td>Greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hello</td>\n",
       "      <td>Greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hello there</td>\n",
       "      <td>Greeting</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     questions    labels\n",
       "0           Hi  Greeting\n",
       "1     Hi there  Greeting\n",
       "2         Hola  Greeting\n",
       "3        Hello  Greeting\n",
       "4  Hello there  Greeting"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1=pullData('questions','labels',True)\n",
    "data1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi human, please tell me your GeniSys user</td>\n",
       "      <td>Greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hello human, please tell me your GeniSys user</td>\n",
       "      <td>Greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hola human, please tell me your GeniSys user</td>\n",
       "      <td>Greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Great! Hi &lt;HUMAN&gt;! How can I help?</td>\n",
       "      <td>GreetingResponse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Good! Hi &lt;HUMAN&gt;, how can I help you?</td>\n",
       "      <td>GreetingResponse</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        response            labels\n",
       "0     Hi human, please tell me your GeniSys user          Greeting\n",
       "1  Hello human, please tell me your GeniSys user          Greeting\n",
       "2   Hola human, please tell me your GeniSys user          Greeting\n",
       "3             Great! Hi <HUMAN>! How can I help?  GreetingResponse\n",
       "4          Good! Hi <HUMAN>, how can I help you?  GreetingResponse"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2=pullData('response','labels',False)\n",
    "data2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/Admin/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "vocab = Counter()\n",
    "labels = []\n",
    "def tokenizer(entry):\n",
    "    tokens = entry.split()\n",
    "    re_punc = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "    tokens = [re_punc.sub('', w) for w in tokens]\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    tokens = [lemmatizer.lemmatize(w.lower()) for w in tokens]\n",
    "    tokens = [word.lower() for word in tokens if len(word) > 1]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopWords(tokenizer,df,feature):\n",
    "    withoutStopwords = []\n",
    "    for entry in df[feature]:\n",
    "        tokens = tokenizer(entry)\n",
    "        joblib.dump(tokens,'tokens.pkl')\n",
    "        withoutStopwords.append(' '.join(tokens))\n",
    "    df[feature] = withoutStopwords\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create(tokenizer,df,feature):\n",
    "    for entry in df[feature]:\n",
    "        tokens = tokenizer(entry)   \n",
    "        vocab.update(tokens)\n",
    "    joblib.dump(vocab,'vocab.pkl')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "create(tokenizer,data1,'questions')\n",
    "stopWords(tokenizer,data1,'questions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hi</td>\n",
       "      <td>Greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hi there</td>\n",
       "      <td>Greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hola</td>\n",
       "      <td>Greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hello</td>\n",
       "      <td>Greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hello there</td>\n",
       "      <td>Greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hya</td>\n",
       "      <td>Greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hya there</td>\n",
       "      <td>Greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>my user is adam</td>\n",
       "      <td>GreetingResponse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>this is adam</td>\n",
       "      <td>GreetingResponse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>am adam</td>\n",
       "      <td>GreetingResponse</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         questions            labels\n",
       "0               hi          Greeting\n",
       "1         hi there          Greeting\n",
       "2             hola          Greeting\n",
       "3            hello          Greeting\n",
       "4      hello there          Greeting\n",
       "5              hya          Greeting\n",
       "6        hya there          Greeting\n",
       "7  my user is adam  GreetingResponse\n",
       "8     this is adam  GreetingResponse\n",
       "9          am adam  GreetingResponse"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['you are very clever',\n",
       " 'thanks bye',\n",
       " 'how are you',\n",
       " 'good thanks my user is adam',\n",
       " 'what is my name',\n",
       " 'bye',\n",
       " 'am bored gossip with me',\n",
       " 'hi',\n",
       " 'my user is adam',\n",
       " 'tell me joke',\n",
       " 'what is your name',\n",
       " 'am not talking to you',\n",
       " 'open the pod bay door',\n",
       " 'why',\n",
       " 'what is your real name',\n",
       " 'can you prove you are selfaware',\n",
       " 'be quiet',\n",
       " 'fuck off',\n",
       " 'ok thank you',\n",
       " 'what is the time',\n",
       " 'do you understand what am saying',\n",
       " 'can you see me']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_list = list(data1.groupby(by='labels',as_index=False).first()['questions'])\n",
    "test_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[103,\n",
       " 91,\n",
       " 15,\n",
       " 22,\n",
       " 30,\n",
       " 87,\n",
       " 110,\n",
       " 0,\n",
       " 7,\n",
       " 116,\n",
       " 37,\n",
       " 63,\n",
       " 122,\n",
       " 129,\n",
       " 43,\n",
       " 136,\n",
       " 76,\n",
       " 83,\n",
       " 57,\n",
       " 50,\n",
       " 70,\n",
       " 97]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_index = []\n",
    "for i,_ in enumerate(test_list):\n",
    "    idx = data1[data1.questions == test_list[i]].index[0]\n",
    "    test_index.append(idx)\n",
    "test_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index = [i for i in data1.index if i not in test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(df,feature):\n",
    "    t = Tokenizer()\n",
    "    entries = [entry for entry in df[feature]]\n",
    "    t.fit_on_texts(entries)\n",
    "    joblib.dump(t,'tokenizer_t.pkl')\n",
    "    vocab_size = len(t.word_index) + 1\n",
    "    entries = [entry for entry in df[feature]]\n",
    "    max_length = max([len(s.split()) for s in entries])\n",
    "    encoded = t.texts_to_sequences(entries)\n",
    "    padded = pad_sequences(encoded, maxlen=max_length, padding='post')\n",
    "    return padded, vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded,vocab_size = encoder(data1,'questions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded=pd.DataFrame(padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Greeting</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1  2  3  4  5  6  7  8    labels\n",
       "0  47   0  0  0  0  0  0  0  0  Greeting\n",
       "1  47  48  0  0  0  0  0  0  0  Greeting\n",
       "2  61   0  0  0  0  0  0  0  0  Greeting\n",
       "3  36   0  0  0  0  0  0  0  0  Greeting\n",
       "4  36  48  0  0  0  0  0  0  0  Greeting"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded['labels']=data1.labels\n",
    "encoded.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7,  7,  7,  7,  7,  7,  7,  8,  8,  8,  8,  8,  8,  8,  8,  2,  2,\n",
       "        2,  2,  2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  3,  4,  4,  4,  4,\n",
       "        4,  4,  4, 10, 10, 10, 10, 10, 10, 14, 14, 14, 14, 14, 14, 14, 19,\n",
       "       19, 19, 19, 19, 19, 19, 18, 18, 18, 18, 18, 18, 11, 11, 11, 11, 11,\n",
       "       11, 11, 20, 20, 20, 20, 20, 20, 16, 16, 16, 16, 16, 16, 16, 17, 17,\n",
       "       17, 17,  5,  5,  5,  5,  1,  1,  1,  1,  1,  1, 21, 21, 21, 21, 21,\n",
       "       21,  0,  0,  0,  0,  0,  0,  0,  6,  6,  6,  6,  6,  6,  9,  9,  9,\n",
       "        9,  9,  9, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13,\n",
       "       15, 15, 15, 15, 15, 15, 15])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labell=labelencoder.fit_transform(encoded.labels)\n",
    "labell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Greeting': 7,\n",
       " 'GreetingResponse': 8,\n",
       " 'CourtesyGreeting': 2,\n",
       " 'CourtesyGreetingResponse': 3,\n",
       " 'CurrentHumanQuery': 4,\n",
       " 'NameQuery': 10,\n",
       " 'RealNameQuery': 14,\n",
       " 'TimeQuery': 19,\n",
       " 'Thanks': 18,\n",
       " 'NotTalking2U': 11,\n",
       " 'UnderstandQuery': 20,\n",
       " 'Shutup': 16,\n",
       " 'Swearing': 17,\n",
       " 'GoodBye': 5,\n",
       " 'CourtesyGoodBye': 1,\n",
       " 'WhoAmI': 21,\n",
       " 'Clever': 0,\n",
       " 'Gossip': 6,\n",
       " 'Jokes': 9,\n",
       " 'PodBayDoor': 12,\n",
       " 'PodBayDoorResponse': 13,\n",
       " 'SelfAware': 15}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapper = {}\n",
    "for index,key in enumerate(encoded.labels):\n",
    "    if key not in mapper.keys():\n",
    "        mapper[key] = labell[index]\n",
    "mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi human, please tell me your GeniSys user</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hello human, please tell me your GeniSys user</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hola human, please tell me your GeniSys user</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Great! Hi &lt;HUMAN&gt;! How can I help?</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Good! Hi &lt;HUMAN&gt;, how can I help you?</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        response  labels\n",
       "0     Hi human, please tell me your GeniSys user       7\n",
       "1  Hello human, please tell me your GeniSys user       7\n",
       "2   Hola human, please tell me your GeniSys user       7\n",
       "3             Great! Hi <HUMAN>! How can I help?       8\n",
       "4          Good! Hi <HUMAN>, how can I help you?       8"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.labels = data2.labels.map(mapper).astype({'labels': 'int32'})\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.to_csv('response.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = encoded.loc[train_index]\n",
    "test = encoded.loc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=train.drop(columns=['labels'],axis=1)\n",
    "y_train=train.labels\n",
    "X_test=test.drop(columns=['labels'],axis=1)\n",
    "y_test=test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train =pd.get_dummies(y_train).values\n",
    "y_test =pd.get_dummies(y_test).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length=X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(121, 22)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def define_model(vocab_size,max_length):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size,300, input_length=max_length))\n",
    "    model.add(Conv1D(filters=64, kernel_size=4, activation='relu'))\n",
    "    model.add(Flatten())\n",
    "#     model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(22, activation='softmax'))\n",
    "    \n",
    "    \n",
    "    # compile network\n",
    "#     model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.compile(loss = 'categorical_crossentropy',\n",
    "              # optimizer = Adam(lr=0.001),\n",
    "              optimizer = 'adam',\n",
    "              metrics = ['accuracy'])\n",
    "    \n",
    "    # summarize defined model\n",
    "    model.summary()\n",
    "#     plot_model(model, to_file='model.png', show_shapes=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 9, 300)            34500     \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 6, 64)             76864     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 22)                8470      \n",
      "=================================================================\n",
      "Total params: 119,834\n",
      "Trainable params: 119,834\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = define_model(vocab_size,max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Admin/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 121 samples, validate on 22 samples\n",
      "Epoch 1/500\n",
      "121/121 [==============================] - 2s 18ms/step - loss: 3.0871 - acc: 0.0744 - val_loss: 3.0579 - val_acc: 0.1818\n",
      "Epoch 2/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 3.0039 - acc: 0.3306 - val_loss: 3.0167 - val_acc: 0.2727\n",
      "Epoch 3/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.9250 - acc: 0.4380 - val_loss: 2.9637 - val_acc: 0.2727\n",
      "Epoch 4/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.8310 - acc: 0.5289 - val_loss: 2.9013 - val_acc: 0.2727\n",
      "Epoch 5/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.7154 - acc: 0.6116 - val_loss: 2.8247 - val_acc: 0.3636\n",
      "Epoch 6/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.5900 - acc: 0.6777 - val_loss: 2.7378 - val_acc: 0.3636\n",
      "Epoch 7/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.4318 - acc: 0.7438 - val_loss: 2.6385 - val_acc: 0.4545\n",
      "Epoch 8/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.2673 - acc: 0.7438 - val_loss: 2.5239 - val_acc: 0.5000\n",
      "Epoch 9/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.0841 - acc: 0.7273 - val_loss: 2.3975 - val_acc: 0.5000\n",
      "Epoch 10/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.9032 - acc: 0.7355 - val_loss: 2.2710 - val_acc: 0.4545\n",
      "Epoch 11/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.7147 - acc: 0.7355 - val_loss: 2.1280 - val_acc: 0.5000\n",
      "Epoch 12/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.5311 - acc: 0.7769 - val_loss: 1.9862 - val_acc: 0.5455\n",
      "Epoch 13/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.3643 - acc: 0.8099 - val_loss: 1.8558 - val_acc: 0.5455\n",
      "Epoch 14/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.2104 - acc: 0.8099 - val_loss: 1.7292 - val_acc: 0.5455\n",
      "Epoch 15/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.0593 - acc: 0.8430 - val_loss: 1.6167 - val_acc: 0.5909\n",
      "Epoch 16/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.9364 - acc: 0.8347 - val_loss: 1.5157 - val_acc: 0.6364\n",
      "Epoch 17/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.8328 - acc: 0.8843 - val_loss: 1.4013 - val_acc: 0.6818\n",
      "Epoch 18/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.7334 - acc: 0.9008 - val_loss: 1.3226 - val_acc: 0.6818\n",
      "Epoch 19/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.6462 - acc: 0.9339 - val_loss: 1.2619 - val_acc: 0.6364\n",
      "Epoch 20/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.5751 - acc: 0.9256 - val_loss: 1.2144 - val_acc: 0.6364\n",
      "Epoch 21/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.5052 - acc: 0.9339 - val_loss: 1.1738 - val_acc: 0.6364\n",
      "Epoch 22/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.4441 - acc: 0.9587 - val_loss: 1.1196 - val_acc: 0.6818\n",
      "Epoch 23/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3983 - acc: 0.9587 - val_loss: 1.0772 - val_acc: 0.6364\n",
      "Epoch 24/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3494 - acc: 0.9669 - val_loss: 1.0325 - val_acc: 0.6364\n",
      "Epoch 25/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3091 - acc: 0.9669 - val_loss: 1.0068 - val_acc: 0.6364\n",
      "Epoch 26/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.2762 - acc: 0.9752 - val_loss: 0.9897 - val_acc: 0.6364\n",
      "Epoch 27/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.2450 - acc: 0.9835 - val_loss: 0.9648 - val_acc: 0.6364\n",
      "Epoch 28/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.2169 - acc: 0.9752 - val_loss: 0.9316 - val_acc: 0.6818\n",
      "Epoch 29/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.1920 - acc: 0.9835 - val_loss: 0.9058 - val_acc: 0.6818\n",
      "Epoch 30/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.1722 - acc: 1.0000 - val_loss: 0.8790 - val_acc: 0.6818\n",
      "Epoch 31/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.1543 - acc: 1.0000 - val_loss: 0.8561 - val_acc: 0.6818\n",
      "Epoch 32/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.1380 - acc: 1.0000 - val_loss: 0.8460 - val_acc: 0.6818\n",
      "Epoch 33/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.1231 - acc: 1.0000 - val_loss: 0.8383 - val_acc: 0.6818\n",
      "Epoch 34/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.1117 - acc: 1.0000 - val_loss: 0.8229 - val_acc: 0.7273\n",
      "Epoch 35/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0996 - acc: 0.9917 - val_loss: 0.8015 - val_acc: 0.7273\n",
      "Epoch 36/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0894 - acc: 1.0000 - val_loss: 0.7780 - val_acc: 0.7273\n",
      "Epoch 37/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0777 - acc: 1.0000 - val_loss: 0.7723 - val_acc: 0.7273\n",
      "Epoch 38/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0712 - acc: 1.0000 - val_loss: 0.7655 - val_acc: 0.7273\n",
      "Epoch 39/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0636 - acc: 1.0000 - val_loss: 0.7575 - val_acc: 0.7273\n",
      "Epoch 40/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0576 - acc: 1.0000 - val_loss: 0.7492 - val_acc: 0.7273\n",
      "Epoch 41/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0530 - acc: 1.0000 - val_loss: 0.7404 - val_acc: 0.7273\n",
      "Epoch 42/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0492 - acc: 1.0000 - val_loss: 0.7304 - val_acc: 0.7273\n",
      "Epoch 43/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0442 - acc: 1.0000 - val_loss: 0.7281 - val_acc: 0.7273\n",
      "Epoch 44/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0403 - acc: 1.0000 - val_loss: 0.7204 - val_acc: 0.7273\n",
      "Epoch 45/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0383 - acc: 1.0000 - val_loss: 0.7054 - val_acc: 0.7273\n",
      "Epoch 46/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0347 - acc: 1.0000 - val_loss: 0.6933 - val_acc: 0.7273\n",
      "Epoch 47/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0316 - acc: 1.0000 - val_loss: 0.6918 - val_acc: 0.7273\n",
      "Epoch 48/500\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.0293 - acc: 1.0000 - val_loss: 0.6907 - val_acc: 0.7273\n",
      "Epoch 49/500\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.0278 - acc: 1.0000 - val_loss: 0.6871 - val_acc: 0.7273\n",
      "Epoch 50/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0254 - acc: 1.0000 - val_loss: 0.6917 - val_acc: 0.7273\n",
      "Epoch 51/500\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.0245 - acc: 1.0000 - val_loss: 0.6954 - val_acc: 0.7273\n",
      "Epoch 52/500\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.0230 - acc: 1.0000 - val_loss: 0.6829 - val_acc: 0.7273\n",
      "Epoch 53/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0210 - acc: 1.0000 - val_loss: 0.6755 - val_acc: 0.7273\n",
      "Epoch 54/500\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.0196 - acc: 1.0000 - val_loss: 0.6656 - val_acc: 0.7273\n",
      "Epoch 55/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0185 - acc: 1.0000 - val_loss: 0.6615 - val_acc: 0.7273\n",
      "Epoch 56/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0176 - acc: 1.0000 - val_loss: 0.6601 - val_acc: 0.7273\n",
      "Epoch 57/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0167 - acc: 1.0000 - val_loss: 0.6563 - val_acc: 0.7273\n",
      "Epoch 58/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0158 - acc: 1.0000 - val_loss: 0.6598 - val_acc: 0.7273\n",
      "Epoch 59/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0152 - acc: 1.0000 - val_loss: 0.6632 - val_acc: 0.7273\n",
      "Epoch 60/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0143 - acc: 1.0000 - val_loss: 0.6539 - val_acc: 0.7273\n",
      "Epoch 61/500\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.0134 - acc: 1.0000 - val_loss: 0.6499 - val_acc: 0.7273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0128 - acc: 1.0000 - val_loss: 0.6506 - val_acc: 0.7273\n",
      "Epoch 63/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0122 - acc: 1.0000 - val_loss: 0.6512 - val_acc: 0.7273\n",
      "Epoch 64/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0117 - acc: 1.0000 - val_loss: 0.6460 - val_acc: 0.7273\n",
      "Epoch 65/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0112 - acc: 1.0000 - val_loss: 0.6436 - val_acc: 0.7273\n",
      "Epoch 66/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0107 - acc: 1.0000 - val_loss: 0.6426 - val_acc: 0.7273\n",
      "Epoch 67/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0102 - acc: 1.0000 - val_loss: 0.6469 - val_acc: 0.7273\n",
      "Epoch 68/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0099 - acc: 1.0000 - val_loss: 0.6455 - val_acc: 0.7273\n",
      "Epoch 69/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0095 - acc: 1.0000 - val_loss: 0.6424 - val_acc: 0.7273\n",
      "Epoch 70/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0091 - acc: 1.0000 - val_loss: 0.6377 - val_acc: 0.7273\n",
      "Epoch 71/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0087 - acc: 1.0000 - val_loss: 0.6329 - val_acc: 0.7273\n",
      "Epoch 72/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0084 - acc: 1.0000 - val_loss: 0.6316 - val_acc: 0.7273\n",
      "Epoch 73/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0081 - acc: 1.0000 - val_loss: 0.6316 - val_acc: 0.7273\n",
      "Epoch 74/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0079 - acc: 1.0000 - val_loss: 0.6334 - val_acc: 0.7273\n",
      "Epoch 75/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0076 - acc: 1.0000 - val_loss: 0.6314 - val_acc: 0.7273\n",
      "Epoch 76/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0073 - acc: 1.0000 - val_loss: 0.6284 - val_acc: 0.7273\n",
      "Epoch 77/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0071 - acc: 1.0000 - val_loss: 0.6286 - val_acc: 0.7273\n",
      "Epoch 78/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0068 - acc: 1.0000 - val_loss: 0.6285 - val_acc: 0.7273\n",
      "Epoch 79/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0066 - acc: 1.0000 - val_loss: 0.6275 - val_acc: 0.7273\n",
      "Epoch 80/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0064 - acc: 1.0000 - val_loss: 0.6297 - val_acc: 0.7273\n",
      "Epoch 81/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0062 - acc: 1.0000 - val_loss: 0.6291 - val_acc: 0.7273\n",
      "Epoch 82/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0060 - acc: 1.0000 - val_loss: 0.6261 - val_acc: 0.7273\n",
      "Epoch 83/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0058 - acc: 1.0000 - val_loss: 0.6262 - val_acc: 0.7273\n",
      "Epoch 84/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0056 - acc: 1.0000 - val_loss: 0.6276 - val_acc: 0.7273\n",
      "Epoch 85/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0055 - acc: 1.0000 - val_loss: 0.6268 - val_acc: 0.7273\n",
      "Epoch 86/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0053 - acc: 1.0000 - val_loss: 0.6249 - val_acc: 0.7273\n",
      "Epoch 87/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0052 - acc: 1.0000 - val_loss: 0.6232 - val_acc: 0.7273\n",
      "Epoch 88/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0050 - acc: 1.0000 - val_loss: 0.6209 - val_acc: 0.7273\n",
      "Epoch 89/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0049 - acc: 1.0000 - val_loss: 0.6206 - val_acc: 0.7273\n",
      "Epoch 90/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0048 - acc: 1.0000 - val_loss: 0.6186 - val_acc: 0.7273\n",
      "Epoch 91/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.6197 - val_acc: 0.7273\n",
      "Epoch 92/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.6191 - val_acc: 0.7273\n",
      "Epoch 93/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.6174 - val_acc: 0.7273\n",
      "Epoch 94/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.6161 - val_acc: 0.7273\n",
      "Epoch 95/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.6155 - val_acc: 0.7273\n",
      "Epoch 96/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.6165 - val_acc: 0.7273\n",
      "Epoch 97/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.6165 - val_acc: 0.7273\n",
      "Epoch 98/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.6154 - val_acc: 0.7273\n",
      "Epoch 99/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.6150 - val_acc: 0.7727\n",
      "Epoch 100/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.6147 - val_acc: 0.7727\n",
      "Epoch 101/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.6126 - val_acc: 0.7727\n",
      "Epoch 102/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.6126 - val_acc: 0.7273\n",
      "Epoch 103/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.6132 - val_acc: 0.7273\n",
      "Epoch 104/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.6104 - val_acc: 0.7273\n",
      "Epoch 105/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.6079 - val_acc: 0.7273\n",
      "Epoch 106/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.6074 - val_acc: 0.7727\n",
      "Epoch 107/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.6086 - val_acc: 0.7727\n",
      "Epoch 108/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.6092 - val_acc: 0.7727\n",
      "Epoch 109/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.6091 - val_acc: 0.7273\n",
      "Epoch 110/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.6097 - val_acc: 0.7273\n",
      "Epoch 111/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.6097 - val_acc: 0.7273\n",
      "Epoch 112/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.6094 - val_acc: 0.7727\n",
      "Epoch 113/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.6079 - val_acc: 0.7727\n",
      "Epoch 114/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.6067 - val_acc: 0.7727\n",
      "Epoch 115/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.6070 - val_acc: 0.7273\n",
      "Epoch 116/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.6049 - val_acc: 0.7273\n",
      "Epoch 117/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.6058 - val_acc: 0.7727\n",
      "Epoch 118/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.6040 - val_acc: 0.7727\n",
      "Epoch 119/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.6037 - val_acc: 0.7727\n",
      "Epoch 120/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.6040 - val_acc: 0.7727\n",
      "Epoch 121/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.6036 - val_acc: 0.7727\n",
      "Epoch 122/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.6050 - val_acc: 0.7727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.6069 - val_acc: 0.7727\n",
      "Epoch 124/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.6084 - val_acc: 0.7273\n",
      "Epoch 125/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.6084 - val_acc: 0.7273\n",
      "Epoch 126/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.6068 - val_acc: 0.7273\n",
      "Epoch 127/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.6076 - val_acc: 0.7273\n",
      "Epoch 128/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.6068 - val_acc: 0.7273\n",
      "Epoch 129/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.6065 - val_acc: 0.7727\n",
      "Epoch 130/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.6077 - val_acc: 0.7727\n",
      "Epoch 131/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.6088 - val_acc: 0.7727\n",
      "Epoch 132/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.6068 - val_acc: 0.7273\n",
      "Epoch 133/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.6054 - val_acc: 0.7273\n",
      "Epoch 134/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.6048 - val_acc: 0.7727\n",
      "Epoch 135/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.6044 - val_acc: 0.7727\n",
      "Epoch 136/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.6031 - val_acc: 0.7727\n",
      "Epoch 137/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.6035 - val_acc: 0.7727\n",
      "Epoch 138/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.6039 - val_acc: 0.7727\n",
      "Epoch 139/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.6036 - val_acc: 0.7727\n",
      "Epoch 140/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.6014 - val_acc: 0.7727\n",
      "Epoch 141/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.6002 - val_acc: 0.7727\n",
      "Epoch 142/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.6001 - val_acc: 0.7727\n",
      "Epoch 143/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.5998 - val_acc: 0.7727\n",
      "Epoch 144/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.5990 - val_acc: 0.7727\n",
      "Epoch 145/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.5995 - val_acc: 0.7727\n",
      "Epoch 146/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.6018 - val_acc: 0.7727\n",
      "Epoch 147/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.6015 - val_acc: 0.7727\n",
      "Epoch 148/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.6027 - val_acc: 0.7727\n",
      "Epoch 149/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.6023 - val_acc: 0.7727\n",
      "Epoch 150/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.6027 - val_acc: 0.7727\n",
      "Epoch 151/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.6030 - val_acc: 0.7727\n",
      "Epoch 152/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.6019 - val_acc: 0.7727\n",
      "Epoch 153/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.6015 - val_acc: 0.7727\n",
      "Epoch 154/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.6009 - val_acc: 0.7727\n",
      "Epoch 155/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.6003 - val_acc: 0.7727\n",
      "Epoch 156/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.6012 - val_acc: 0.7727\n",
      "Epoch 157/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.6003 - val_acc: 0.7727\n",
      "Epoch 158/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.6008 - val_acc: 0.7727\n",
      "Epoch 159/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.6013 - val_acc: 0.7727\n",
      "Epoch 160/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.6003 - val_acc: 0.7727\n",
      "Epoch 161/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.6006 - val_acc: 0.7727\n",
      "Epoch 162/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.6011 - val_acc: 0.7727\n",
      "Epoch 163/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.6014 - val_acc: 0.7727\n",
      "Epoch 164/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.5985 - val_acc: 0.7727\n",
      "Epoch 165/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.5981 - val_acc: 0.7727\n",
      "Epoch 166/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.5982 - val_acc: 0.7727\n",
      "Epoch 167/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.5985 - val_acc: 0.7727\n",
      "Epoch 168/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.5981 - val_acc: 0.7727\n",
      "Epoch 169/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.5987 - val_acc: 0.7727\n",
      "Epoch 170/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.5988 - val_acc: 0.7727\n",
      "Epoch 171/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.5972 - val_acc: 0.7727\n",
      "Epoch 172/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.5983 - val_acc: 0.7727\n",
      "Epoch 173/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.5985 - val_acc: 0.7727\n",
      "Epoch 174/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.5985 - val_acc: 0.7727\n",
      "Epoch 175/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.5984 - val_acc: 0.7727\n",
      "Epoch 176/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.5973 - val_acc: 0.7727\n",
      "Epoch 177/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.5971 - val_acc: 0.7727\n",
      "Epoch 178/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.5964 - val_acc: 0.7727\n",
      "Epoch 179/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.5961 - val_acc: 0.7727\n",
      "Epoch 180/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.5964 - val_acc: 0.7727\n",
      "Epoch 181/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.5960 - val_acc: 0.7727\n",
      "Epoch 182/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.5965 - val_acc: 0.7727\n",
      "Epoch 183/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121/121 [==============================] - 0s 1ms/step - loss: 9.9241e-04 - acc: 1.0000 - val_loss: 0.5972 - val_acc: 0.7727\n",
      "Epoch 184/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 9.8081e-04 - acc: 1.0000 - val_loss: 0.5962 - val_acc: 0.7727\n",
      "Epoch 185/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 9.6925e-04 - acc: 1.0000 - val_loss: 0.5962 - val_acc: 0.7727\n",
      "Epoch 186/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 9.6039e-04 - acc: 1.0000 - val_loss: 0.5947 - val_acc: 0.7727\n",
      "Epoch 187/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 9.4807e-04 - acc: 1.0000 - val_loss: 0.5952 - val_acc: 0.7727\n",
      "Epoch 188/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 9.3665e-04 - acc: 1.0000 - val_loss: 0.5948 - val_acc: 0.7727\n",
      "Epoch 189/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 9.2662e-04 - acc: 1.0000 - val_loss: 0.5947 - val_acc: 0.7727\n",
      "Epoch 190/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 9.1706e-04 - acc: 1.0000 - val_loss: 0.5956 - val_acc: 0.7727\n",
      "Epoch 191/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 9.0705e-04 - acc: 1.0000 - val_loss: 0.5949 - val_acc: 0.7727\n",
      "Epoch 192/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 8.9688e-04 - acc: 1.0000 - val_loss: 0.5952 - val_acc: 0.7727\n",
      "Epoch 193/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 8.8763e-04 - acc: 1.0000 - val_loss: 0.5952 - val_acc: 0.7727\n",
      "Epoch 194/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 8.7813e-04 - acc: 1.0000 - val_loss: 0.5961 - val_acc: 0.7727\n",
      "Epoch 195/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 8.6839e-04 - acc: 1.0000 - val_loss: 0.5968 - val_acc: 0.7727\n",
      "Epoch 196/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 8.5918e-04 - acc: 1.0000 - val_loss: 0.5964 - val_acc: 0.7727\n",
      "Epoch 197/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 8.5064e-04 - acc: 1.0000 - val_loss: 0.5979 - val_acc: 0.7727\n",
      "Epoch 198/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 8.4185e-04 - acc: 1.0000 - val_loss: 0.5974 - val_acc: 0.7727\n",
      "Epoch 199/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 8.3257e-04 - acc: 1.0000 - val_loss: 0.5970 - val_acc: 0.7727\n",
      "Epoch 200/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 8.2440e-04 - acc: 1.0000 - val_loss: 0.5965 - val_acc: 0.7727\n",
      "Epoch 201/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 8.1550e-04 - acc: 1.0000 - val_loss: 0.5953 - val_acc: 0.7727\n",
      "Epoch 202/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 8.0822e-04 - acc: 1.0000 - val_loss: 0.5968 - val_acc: 0.7727\n",
      "Epoch 203/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 7.9863e-04 - acc: 1.0000 - val_loss: 0.5966 - val_acc: 0.7727\n",
      "Epoch 204/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 7.9160e-04 - acc: 1.0000 - val_loss: 0.5964 - val_acc: 0.7727\n",
      "Epoch 205/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 7.8393e-04 - acc: 1.0000 - val_loss: 0.5960 - val_acc: 0.7727\n",
      "Epoch 206/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 7.7473e-04 - acc: 1.0000 - val_loss: 0.5965 - val_acc: 0.7727\n",
      "Epoch 207/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 7.6692e-04 - acc: 1.0000 - val_loss: 0.5965 - val_acc: 0.7727\n",
      "Epoch 208/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 7.5973e-04 - acc: 1.0000 - val_loss: 0.5973 - val_acc: 0.7727\n",
      "Epoch 209/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 7.5214e-04 - acc: 1.0000 - val_loss: 0.5981 - val_acc: 0.7727\n",
      "Epoch 210/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 7.4435e-04 - acc: 1.0000 - val_loss: 0.5981 - val_acc: 0.7727\n",
      "Epoch 211/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 7.3740e-04 - acc: 1.0000 - val_loss: 0.5976 - val_acc: 0.7727\n",
      "Epoch 212/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 7.3083e-04 - acc: 1.0000 - val_loss: 0.5978 - val_acc: 0.7727\n",
      "Epoch 213/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 7.2333e-04 - acc: 1.0000 - val_loss: 0.5963 - val_acc: 0.7727\n",
      "Epoch 214/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 7.1661e-04 - acc: 1.0000 - val_loss: 0.5962 - val_acc: 0.7727\n",
      "Epoch 215/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 7.0904e-04 - acc: 1.0000 - val_loss: 0.5968 - val_acc: 0.7727\n",
      "Epoch 216/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 7.0296e-04 - acc: 1.0000 - val_loss: 0.5972 - val_acc: 0.7727\n",
      "Epoch 217/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 6.9542e-04 - acc: 1.0000 - val_loss: 0.5972 - val_acc: 0.7727\n",
      "Epoch 218/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 6.8919e-04 - acc: 1.0000 - val_loss: 0.5969 - val_acc: 0.7727\n",
      "Epoch 219/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 6.8301e-04 - acc: 1.0000 - val_loss: 0.5967 - val_acc: 0.7727\n",
      "Epoch 220/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 6.7639e-04 - acc: 1.0000 - val_loss: 0.5961 - val_acc: 0.7727\n",
      "Epoch 221/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 6.6960e-04 - acc: 1.0000 - val_loss: 0.5959 - val_acc: 0.7727\n",
      "Epoch 222/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 6.6355e-04 - acc: 1.0000 - val_loss: 0.5962 - val_acc: 0.7727\n",
      "Epoch 223/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 6.5738e-04 - acc: 1.0000 - val_loss: 0.5963 - val_acc: 0.7727\n",
      "Epoch 224/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 6.5112e-04 - acc: 1.0000 - val_loss: 0.5966 - val_acc: 0.7727\n",
      "Epoch 225/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 6.4552e-04 - acc: 1.0000 - val_loss: 0.5967 - val_acc: 0.7727\n",
      "Epoch 226/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 6.3942e-04 - acc: 1.0000 - val_loss: 0.5963 - val_acc: 0.7727\n",
      "Epoch 227/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 6.3378e-04 - acc: 1.0000 - val_loss: 0.5967 - val_acc: 0.7727\n",
      "Epoch 228/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 6.2793e-04 - acc: 1.0000 - val_loss: 0.5966 - val_acc: 0.7727\n",
      "Epoch 229/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 6.2264e-04 - acc: 1.0000 - val_loss: 0.5959 - val_acc: 0.7727\n",
      "Epoch 230/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 6.1724e-04 - acc: 1.0000 - val_loss: 0.5967 - val_acc: 0.7727\n",
      "Epoch 231/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 6.1122e-04 - acc: 1.0000 - val_loss: 0.5972 - val_acc: 0.7727\n",
      "Epoch 232/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 6.0572e-04 - acc: 1.0000 - val_loss: 0.5968 - val_acc: 0.7727\n",
      "Epoch 233/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 6.0066e-04 - acc: 1.0000 - val_loss: 0.5966 - val_acc: 0.7727\n",
      "Epoch 234/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 5.9493e-04 - acc: 1.0000 - val_loss: 0.5970 - val_acc: 0.7727\n",
      "Epoch 235/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 5.8970e-04 - acc: 1.0000 - val_loss: 0.5961 - val_acc: 0.7727\n",
      "Epoch 236/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 5.8508e-04 - acc: 1.0000 - val_loss: 0.5949 - val_acc: 0.7727\n",
      "Epoch 237/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 5.7966e-04 - acc: 1.0000 - val_loss: 0.5946 - val_acc: 0.7727\n",
      "Epoch 238/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 5.7431e-04 - acc: 1.0000 - val_loss: 0.5952 - val_acc: 0.7727\n",
      "Epoch 239/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 5.6974e-04 - acc: 1.0000 - val_loss: 0.5953 - val_acc: 0.7727\n",
      "Epoch 240/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 5.6502e-04 - acc: 1.0000 - val_loss: 0.5959 - val_acc: 0.7727\n",
      "Epoch 241/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 5.5967e-04 - acc: 1.0000 - val_loss: 0.5959 - val_acc: 0.7727\n",
      "Epoch 242/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121/121 [==============================] - 0s 1ms/step - loss: 5.5507e-04 - acc: 1.0000 - val_loss: 0.5954 - val_acc: 0.7727\n",
      "Epoch 243/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 5.5008e-04 - acc: 1.0000 - val_loss: 0.5946 - val_acc: 0.7727\n",
      "Epoch 244/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 5.4598e-04 - acc: 1.0000 - val_loss: 0.5943 - val_acc: 0.7727\n",
      "Epoch 245/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 5.4095e-04 - acc: 1.0000 - val_loss: 0.5941 - val_acc: 0.7727\n",
      "Epoch 246/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 5.3619e-04 - acc: 1.0000 - val_loss: 0.5948 - val_acc: 0.7727\n",
      "Epoch 247/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 5.3137e-04 - acc: 1.0000 - val_loss: 0.5951 - val_acc: 0.7727\n",
      "Epoch 248/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 5.2745e-04 - acc: 1.0000 - val_loss: 0.5954 - val_acc: 0.7727\n",
      "Epoch 249/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 5.2303e-04 - acc: 1.0000 - val_loss: 0.5961 - val_acc: 0.7727\n",
      "Epoch 250/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 5.1844e-04 - acc: 1.0000 - val_loss: 0.5957 - val_acc: 0.7727\n",
      "Epoch 251/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 5.1443e-04 - acc: 1.0000 - val_loss: 0.5960 - val_acc: 0.7727\n",
      "Epoch 252/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 5.1052e-04 - acc: 1.0000 - val_loss: 0.5951 - val_acc: 0.7727\n",
      "Epoch 253/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 5.0606e-04 - acc: 1.0000 - val_loss: 0.5952 - val_acc: 0.7727\n",
      "Epoch 254/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 5.0176e-04 - acc: 1.0000 - val_loss: 0.5955 - val_acc: 0.7727\n",
      "Epoch 255/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 4.9769e-04 - acc: 1.0000 - val_loss: 0.5942 - val_acc: 0.7727\n",
      "Epoch 256/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 4.9337e-04 - acc: 1.0000 - val_loss: 0.5943 - val_acc: 0.7727\n",
      "Epoch 257/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 4.8981e-04 - acc: 1.0000 - val_loss: 0.5946 - val_acc: 0.7727\n",
      "Epoch 258/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 4.8558e-04 - acc: 1.0000 - val_loss: 0.5940 - val_acc: 0.7727\n",
      "Epoch 259/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 4.8177e-04 - acc: 1.0000 - val_loss: 0.5939 - val_acc: 0.7727\n",
      "Epoch 260/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 4.7810e-04 - acc: 1.0000 - val_loss: 0.5941 - val_acc: 0.7727\n",
      "Epoch 261/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 4.7434e-04 - acc: 1.0000 - val_loss: 0.5936 - val_acc: 0.7727\n",
      "Epoch 262/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 4.7053e-04 - acc: 1.0000 - val_loss: 0.5938 - val_acc: 0.7727\n",
      "Epoch 263/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 4.6675e-04 - acc: 1.0000 - val_loss: 0.5942 - val_acc: 0.7727\n",
      "Epoch 264/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 4.6303e-04 - acc: 1.0000 - val_loss: 0.5940 - val_acc: 0.7727\n",
      "Epoch 265/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 4.5978e-04 - acc: 1.0000 - val_loss: 0.5948 - val_acc: 0.7727\n",
      "Epoch 266/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 4.5606e-04 - acc: 1.0000 - val_loss: 0.5938 - val_acc: 0.7727\n",
      "Epoch 267/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 4.5251e-04 - acc: 1.0000 - val_loss: 0.5943 - val_acc: 0.7727\n",
      "Epoch 268/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 4.4913e-04 - acc: 1.0000 - val_loss: 0.5936 - val_acc: 0.7727\n",
      "Epoch 269/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 4.4533e-04 - acc: 1.0000 - val_loss: 0.5944 - val_acc: 0.7727\n",
      "Epoch 270/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 4.4212e-04 - acc: 1.0000 - val_loss: 0.5950 - val_acc: 0.7727\n",
      "Epoch 271/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 4.3857e-04 - acc: 1.0000 - val_loss: 0.5956 - val_acc: 0.7727\n",
      "Epoch 272/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 4.3517e-04 - acc: 1.0000 - val_loss: 0.5949 - val_acc: 0.7727\n",
      "Epoch 273/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 4.3197e-04 - acc: 1.0000 - val_loss: 0.5951 - val_acc: 0.7727\n",
      "Epoch 274/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 4.2864e-04 - acc: 1.0000 - val_loss: 0.5951 - val_acc: 0.7727\n",
      "Epoch 275/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 4.2539e-04 - acc: 1.0000 - val_loss: 0.5953 - val_acc: 0.7727\n",
      "Epoch 276/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 4.2224e-04 - acc: 1.0000 - val_loss: 0.5960 - val_acc: 0.7727\n",
      "Epoch 277/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 4.1888e-04 - acc: 1.0000 - val_loss: 0.5953 - val_acc: 0.7727\n",
      "Epoch 278/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 4.1615e-04 - acc: 1.0000 - val_loss: 0.5956 - val_acc: 0.7727\n",
      "Epoch 279/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 4.1266e-04 - acc: 1.0000 - val_loss: 0.5955 - val_acc: 0.7727\n",
      "Epoch 280/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 4.1001e-04 - acc: 1.0000 - val_loss: 0.5950 - val_acc: 0.7727\n",
      "Epoch 281/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 4.0681e-04 - acc: 1.0000 - val_loss: 0.5948 - val_acc: 0.7727\n",
      "Epoch 282/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 4.0373e-04 - acc: 1.0000 - val_loss: 0.5943 - val_acc: 0.7727\n",
      "Epoch 283/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 4.0104e-04 - acc: 1.0000 - val_loss: 0.5949 - val_acc: 0.7727\n",
      "Epoch 284/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 3.9786e-04 - acc: 1.0000 - val_loss: 0.5941 - val_acc: 0.7727\n",
      "Epoch 285/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 3.9521e-04 - acc: 1.0000 - val_loss: 0.5939 - val_acc: 0.7727\n",
      "Epoch 286/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 3.9202e-04 - acc: 1.0000 - val_loss: 0.5936 - val_acc: 0.7727\n",
      "Epoch 287/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 3.8943e-04 - acc: 1.0000 - val_loss: 0.5932 - val_acc: 0.7727\n",
      "Epoch 288/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 3.8648e-04 - acc: 1.0000 - val_loss: 0.5938 - val_acc: 0.7727\n",
      "Epoch 289/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 3.8401e-04 - acc: 1.0000 - val_loss: 0.5943 - val_acc: 0.7727\n",
      "Epoch 290/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 3.8101e-04 - acc: 1.0000 - val_loss: 0.5935 - val_acc: 0.7727\n",
      "Epoch 291/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 3.7815e-04 - acc: 1.0000 - val_loss: 0.5937 - val_acc: 0.7727\n",
      "Epoch 292/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 3.7582e-04 - acc: 1.0000 - val_loss: 0.5930 - val_acc: 0.7727\n",
      "Epoch 293/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 3.7295e-04 - acc: 1.0000 - val_loss: 0.5934 - val_acc: 0.7727\n",
      "Epoch 294/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 3.7034e-04 - acc: 1.0000 - val_loss: 0.5932 - val_acc: 0.7727\n",
      "Epoch 295/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 3.6776e-04 - acc: 1.0000 - val_loss: 0.5931 - val_acc: 0.7727\n",
      "Epoch 296/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 3.6509e-04 - acc: 1.0000 - val_loss: 0.5929 - val_acc: 0.7727\n",
      "Epoch 297/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 3.6249e-04 - acc: 1.0000 - val_loss: 0.5928 - val_acc: 0.7727\n",
      "Epoch 298/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 3.6001e-04 - acc: 1.0000 - val_loss: 0.5938 - val_acc: 0.7727\n",
      "Epoch 299/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 3.5742e-04 - acc: 1.0000 - val_loss: 0.5941 - val_acc: 0.7727\n",
      "Epoch 300/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 3.5495e-04 - acc: 1.0000 - val_loss: 0.5943 - val_acc: 0.7727\n",
      "Epoch 301/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121/121 [==============================] - 0s 1ms/step - loss: 3.5267e-04 - acc: 1.0000 - val_loss: 0.5933 - val_acc: 0.7727\n",
      "Epoch 302/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 3.5004e-04 - acc: 1.0000 - val_loss: 0.5937 - val_acc: 0.7727\n",
      "Epoch 303/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 3.4761e-04 - acc: 1.0000 - val_loss: 0.5942 - val_acc: 0.7727\n",
      "Epoch 304/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 3.4532e-04 - acc: 1.0000 - val_loss: 0.5944 - val_acc: 0.7727\n",
      "Epoch 305/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 3.4295e-04 - acc: 1.0000 - val_loss: 0.5946 - val_acc: 0.7727\n",
      "Epoch 306/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 3.4044e-04 - acc: 1.0000 - val_loss: 0.5949 - val_acc: 0.7727\n",
      "Epoch 307/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 3.3843e-04 - acc: 1.0000 - val_loss: 0.5948 - val_acc: 0.7727\n",
      "Epoch 308/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 3.3601e-04 - acc: 1.0000 - val_loss: 0.5949 - val_acc: 0.7727\n",
      "Epoch 309/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 3.3371e-04 - acc: 1.0000 - val_loss: 0.5950 - val_acc: 0.7727\n",
      "Epoch 310/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 3.3140e-04 - acc: 1.0000 - val_loss: 0.5956 - val_acc: 0.7727\n",
      "Epoch 311/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 3.2917e-04 - acc: 1.0000 - val_loss: 0.5955 - val_acc: 0.7727\n",
      "Epoch 312/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 3.2719e-04 - acc: 1.0000 - val_loss: 0.5949 - val_acc: 0.7727\n",
      "Epoch 313/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 3.2494e-04 - acc: 1.0000 - val_loss: 0.5959 - val_acc: 0.7727\n",
      "Epoch 314/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 3.2279e-04 - acc: 1.0000 - val_loss: 0.5964 - val_acc: 0.7727\n",
      "Epoch 315/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 3.2047e-04 - acc: 1.0000 - val_loss: 0.5967 - val_acc: 0.7727\n",
      "Epoch 316/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 3.1866e-04 - acc: 1.0000 - val_loss: 0.5961 - val_acc: 0.7727\n",
      "Epoch 317/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 3.1651e-04 - acc: 1.0000 - val_loss: 0.5956 - val_acc: 0.7727\n",
      "Epoch 318/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 3.1434e-04 - acc: 1.0000 - val_loss: 0.5954 - val_acc: 0.7727\n",
      "Epoch 319/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 3.1238e-04 - acc: 1.0000 - val_loss: 0.5957 - val_acc: 0.7727\n",
      "Epoch 320/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 3.1031e-04 - acc: 1.0000 - val_loss: 0.5956 - val_acc: 0.7727\n",
      "Epoch 321/500\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 3.0840e-04 - acc: 1.0000 - val_loss: 0.5963 - val_acc: 0.7727\n",
      "Epoch 322/500\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 3.0629e-04 - acc: 1.0000 - val_loss: 0.5957 - val_acc: 0.7727\n",
      "Epoch 323/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 3.0421e-04 - acc: 1.0000 - val_loss: 0.5953 - val_acc: 0.7727\n",
      "Epoch 324/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 3.0228e-04 - acc: 1.0000 - val_loss: 0.5952 - val_acc: 0.7727\n",
      "Epoch 325/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 3.0030e-04 - acc: 1.0000 - val_loss: 0.5954 - val_acc: 0.7727\n",
      "Epoch 326/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.9841e-04 - acc: 1.0000 - val_loss: 0.5954 - val_acc: 0.7727\n",
      "Epoch 327/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.9642e-04 - acc: 1.0000 - val_loss: 0.5958 - val_acc: 0.7727\n",
      "Epoch 328/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.9457e-04 - acc: 1.0000 - val_loss: 0.5949 - val_acc: 0.7727\n",
      "Epoch 329/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.9273e-04 - acc: 1.0000 - val_loss: 0.5943 - val_acc: 0.7727\n",
      "Epoch 330/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.9084e-04 - acc: 1.0000 - val_loss: 0.5942 - val_acc: 0.7727\n",
      "Epoch 331/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.8899e-04 - acc: 1.0000 - val_loss: 0.5941 - val_acc: 0.7727\n",
      "Epoch 332/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.8724e-04 - acc: 1.0000 - val_loss: 0.5937 - val_acc: 0.7727\n",
      "Epoch 333/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.8541e-04 - acc: 1.0000 - val_loss: 0.5936 - val_acc: 0.7727\n",
      "Epoch 334/500\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 2.8358e-04 - acc: 1.0000 - val_loss: 0.5939 - val_acc: 0.7727\n",
      "Epoch 335/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.8174e-04 - acc: 1.0000 - val_loss: 0.5939 - val_acc: 0.7727\n",
      "Epoch 336/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.8013e-04 - acc: 1.0000 - val_loss: 0.5938 - val_acc: 0.7727\n",
      "Epoch 337/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.7822e-04 - acc: 1.0000 - val_loss: 0.5942 - val_acc: 0.7727\n",
      "Epoch 338/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.7672e-04 - acc: 1.0000 - val_loss: 0.5941 - val_acc: 0.7727\n",
      "Epoch 339/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.7482e-04 - acc: 1.0000 - val_loss: 0.5945 - val_acc: 0.7727\n",
      "Epoch 340/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.7323e-04 - acc: 1.0000 - val_loss: 0.5950 - val_acc: 0.7727\n",
      "Epoch 341/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.7144e-04 - acc: 1.0000 - val_loss: 0.5955 - val_acc: 0.7727\n",
      "Epoch 342/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.6976e-04 - acc: 1.0000 - val_loss: 0.5952 - val_acc: 0.7727\n",
      "Epoch 343/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.6820e-04 - acc: 1.0000 - val_loss: 0.5943 - val_acc: 0.7727\n",
      "Epoch 344/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.6639e-04 - acc: 1.0000 - val_loss: 0.5943 - val_acc: 0.7727\n",
      "Epoch 345/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.6481e-04 - acc: 1.0000 - val_loss: 0.5941 - val_acc: 0.7727\n",
      "Epoch 346/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.6324e-04 - acc: 1.0000 - val_loss: 0.5938 - val_acc: 0.7727\n",
      "Epoch 347/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.6154e-04 - acc: 1.0000 - val_loss: 0.5939 - val_acc: 0.7727\n",
      "Epoch 348/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.6008e-04 - acc: 1.0000 - val_loss: 0.5937 - val_acc: 0.7727\n",
      "Epoch 349/500\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 2.5853e-04 - acc: 1.0000 - val_loss: 0.5937 - val_acc: 0.7727\n",
      "Epoch 350/500\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 2.5698e-04 - acc: 1.0000 - val_loss: 0.5936 - val_acc: 0.7727\n",
      "Epoch 351/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.5541e-04 - acc: 1.0000 - val_loss: 0.5932 - val_acc: 0.7727\n",
      "Epoch 352/500\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 2.5370e-04 - acc: 1.0000 - val_loss: 0.5935 - val_acc: 0.7727\n",
      "Epoch 353/500\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 2.5223e-04 - acc: 1.0000 - val_loss: 0.5940 - val_acc: 0.7727\n",
      "Epoch 354/500\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 2.5083e-04 - acc: 1.0000 - val_loss: 0.5947 - val_acc: 0.7727\n",
      "Epoch 355/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.4925e-04 - acc: 1.0000 - val_loss: 0.5952 - val_acc: 0.7727\n",
      "Epoch 356/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.4770e-04 - acc: 1.0000 - val_loss: 0.5954 - val_acc: 0.7727\n",
      "Epoch 357/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.4644e-04 - acc: 1.0000 - val_loss: 0.5953 - val_acc: 0.7727\n",
      "Epoch 358/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.4500e-04 - acc: 1.0000 - val_loss: 0.5948 - val_acc: 0.7727\n",
      "Epoch 359/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.4342e-04 - acc: 1.0000 - val_loss: 0.5951 - val_acc: 0.7727\n",
      "Epoch 360/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121/121 [==============================] - 0s 1ms/step - loss: 2.4198e-04 - acc: 1.0000 - val_loss: 0.5949 - val_acc: 0.7727\n",
      "Epoch 361/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.4061e-04 - acc: 1.0000 - val_loss: 0.5945 - val_acc: 0.7727\n",
      "Epoch 362/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.3937e-04 - acc: 1.0000 - val_loss: 0.5956 - val_acc: 0.7727\n",
      "Epoch 363/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.3770e-04 - acc: 1.0000 - val_loss: 0.5953 - val_acc: 0.7727\n",
      "Epoch 364/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.3635e-04 - acc: 1.0000 - val_loss: 0.5950 - val_acc: 0.7727\n",
      "Epoch 365/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.3515e-04 - acc: 1.0000 - val_loss: 0.5951 - val_acc: 0.7727\n",
      "Epoch 366/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.3377e-04 - acc: 1.0000 - val_loss: 0.5941 - val_acc: 0.7727\n",
      "Epoch 367/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.3236e-04 - acc: 1.0000 - val_loss: 0.5942 - val_acc: 0.7727\n",
      "Epoch 368/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.3099e-04 - acc: 1.0000 - val_loss: 0.5938 - val_acc: 0.7727\n",
      "Epoch 369/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.2962e-04 - acc: 1.0000 - val_loss: 0.5941 - val_acc: 0.7727\n",
      "Epoch 370/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.2848e-04 - acc: 1.0000 - val_loss: 0.5936 - val_acc: 0.7727\n",
      "Epoch 371/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.2693e-04 - acc: 1.0000 - val_loss: 0.5937 - val_acc: 0.7727\n",
      "Epoch 372/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.2574e-04 - acc: 1.0000 - val_loss: 0.5932 - val_acc: 0.7727\n",
      "Epoch 373/500\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 2.2444e-04 - acc: 1.0000 - val_loss: 0.5935 - val_acc: 0.7727\n",
      "Epoch 374/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.2318e-04 - acc: 1.0000 - val_loss: 0.5940 - val_acc: 0.7727\n",
      "Epoch 375/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.2190e-04 - acc: 1.0000 - val_loss: 0.5939 - val_acc: 0.7727\n",
      "Epoch 376/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.2056e-04 - acc: 1.0000 - val_loss: 0.5935 - val_acc: 0.7727\n",
      "Epoch 377/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.1930e-04 - acc: 1.0000 - val_loss: 0.5938 - val_acc: 0.7727\n",
      "Epoch 378/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.1824e-04 - acc: 1.0000 - val_loss: 0.5933 - val_acc: 0.7727\n",
      "Epoch 379/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.1691e-04 - acc: 1.0000 - val_loss: 0.5931 - val_acc: 0.7727\n",
      "Epoch 380/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.1579e-04 - acc: 1.0000 - val_loss: 0.5931 - val_acc: 0.7727\n",
      "Epoch 381/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.1440e-04 - acc: 1.0000 - val_loss: 0.5930 - val_acc: 0.7727\n",
      "Epoch 382/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.1341e-04 - acc: 1.0000 - val_loss: 0.5935 - val_acc: 0.7727\n",
      "Epoch 383/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.1215e-04 - acc: 1.0000 - val_loss: 0.5939 - val_acc: 0.7727\n",
      "Epoch 384/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.1093e-04 - acc: 1.0000 - val_loss: 0.5942 - val_acc: 0.7727\n",
      "Epoch 385/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.0984e-04 - acc: 1.0000 - val_loss: 0.5933 - val_acc: 0.7727\n",
      "Epoch 386/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.0856e-04 - acc: 1.0000 - val_loss: 0.5934 - val_acc: 0.7727\n",
      "Epoch 387/500\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 2.0749e-04 - acc: 1.0000 - val_loss: 0.5931 - val_acc: 0.7727\n",
      "Epoch 388/500\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 2.0632e-04 - acc: 1.0000 - val_loss: 0.5933 - val_acc: 0.7727\n",
      "Epoch 389/500\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 2.0512e-04 - acc: 1.0000 - val_loss: 0.5936 - val_acc: 0.7727\n",
      "Epoch 390/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.0397e-04 - acc: 1.0000 - val_loss: 0.5934 - val_acc: 0.7727\n",
      "Epoch 391/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.0286e-04 - acc: 1.0000 - val_loss: 0.5936 - val_acc: 0.7727\n",
      "Epoch 392/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.0179e-04 - acc: 1.0000 - val_loss: 0.5941 - val_acc: 0.7727\n",
      "Epoch 393/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2.0075e-04 - acc: 1.0000 - val_loss: 0.5940 - val_acc: 0.7727\n",
      "Epoch 394/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.9951e-04 - acc: 1.0000 - val_loss: 0.5948 - val_acc: 0.7727\n",
      "Epoch 395/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.9853e-04 - acc: 1.0000 - val_loss: 0.5956 - val_acc: 0.7727\n",
      "Epoch 396/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.9745e-04 - acc: 1.0000 - val_loss: 0.5955 - val_acc: 0.7727\n",
      "Epoch 397/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.9644e-04 - acc: 1.0000 - val_loss: 0.5952 - val_acc: 0.7727\n",
      "Epoch 398/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.9530e-04 - acc: 1.0000 - val_loss: 0.5955 - val_acc: 0.7727\n",
      "Epoch 399/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.9426e-04 - acc: 1.0000 - val_loss: 0.5956 - val_acc: 0.7727\n",
      "Epoch 400/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.9324e-04 - acc: 1.0000 - val_loss: 0.5952 - val_acc: 0.7727\n",
      "Epoch 401/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.9235e-04 - acc: 1.0000 - val_loss: 0.5960 - val_acc: 0.7727\n",
      "Epoch 402/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.9118e-04 - acc: 1.0000 - val_loss: 0.5961 - val_acc: 0.7727\n",
      "Epoch 403/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.9017e-04 - acc: 1.0000 - val_loss: 0.5957 - val_acc: 0.7727\n",
      "Epoch 404/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.8920e-04 - acc: 1.0000 - val_loss: 0.5960 - val_acc: 0.7727\n",
      "Epoch 405/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.8824e-04 - acc: 1.0000 - val_loss: 0.5960 - val_acc: 0.7727\n",
      "Epoch 406/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.8712e-04 - acc: 1.0000 - val_loss: 0.5957 - val_acc: 0.7727\n",
      "Epoch 407/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.8616e-04 - acc: 1.0000 - val_loss: 0.5957 - val_acc: 0.7727\n",
      "Epoch 408/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.8525e-04 - acc: 1.0000 - val_loss: 0.5952 - val_acc: 0.7727\n",
      "Epoch 409/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.8430e-04 - acc: 1.0000 - val_loss: 0.5953 - val_acc: 0.7727\n",
      "Epoch 410/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.8326e-04 - acc: 1.0000 - val_loss: 0.5953 - val_acc: 0.7727\n",
      "Epoch 411/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.8230e-04 - acc: 1.0000 - val_loss: 0.5952 - val_acc: 0.7727\n",
      "Epoch 412/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.8141e-04 - acc: 1.0000 - val_loss: 0.5959 - val_acc: 0.7727\n",
      "Epoch 413/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.8039e-04 - acc: 1.0000 - val_loss: 0.5961 - val_acc: 0.7727\n",
      "Epoch 414/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.7947e-04 - acc: 1.0000 - val_loss: 0.5964 - val_acc: 0.7727\n",
      "Epoch 415/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.7848e-04 - acc: 1.0000 - val_loss: 0.5968 - val_acc: 0.7727\n",
      "Epoch 416/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.7763e-04 - acc: 1.0000 - val_loss: 0.5970 - val_acc: 0.7727\n",
      "Epoch 417/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.7673e-04 - acc: 1.0000 - val_loss: 0.5972 - val_acc: 0.7727\n",
      "Epoch 418/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.7578e-04 - acc: 1.0000 - val_loss: 0.5969 - val_acc: 0.7727\n",
      "Epoch 419/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121/121 [==============================] - 0s 1ms/step - loss: 1.7491e-04 - acc: 1.0000 - val_loss: 0.5965 - val_acc: 0.7727\n",
      "Epoch 420/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.7402e-04 - acc: 1.0000 - val_loss: 0.5963 - val_acc: 0.7727\n",
      "Epoch 421/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.7304e-04 - acc: 1.0000 - val_loss: 0.5965 - val_acc: 0.7727\n",
      "Epoch 422/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.7218e-04 - acc: 1.0000 - val_loss: 0.5969 - val_acc: 0.7727\n",
      "Epoch 423/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.7124e-04 - acc: 1.0000 - val_loss: 0.5968 - val_acc: 0.7727\n",
      "Epoch 424/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.7040e-04 - acc: 1.0000 - val_loss: 0.5972 - val_acc: 0.7727\n",
      "Epoch 425/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.6955e-04 - acc: 1.0000 - val_loss: 0.5973 - val_acc: 0.7727\n",
      "Epoch 426/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.6866e-04 - acc: 1.0000 - val_loss: 0.5969 - val_acc: 0.7727\n",
      "Epoch 427/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.6782e-04 - acc: 1.0000 - val_loss: 0.5969 - val_acc: 0.7727\n",
      "Epoch 428/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.6693e-04 - acc: 1.0000 - val_loss: 0.5973 - val_acc: 0.7727\n",
      "Epoch 429/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.6614e-04 - acc: 1.0000 - val_loss: 0.5978 - val_acc: 0.7727\n",
      "Epoch 430/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.6523e-04 - acc: 1.0000 - val_loss: 0.5975 - val_acc: 0.7727\n",
      "Epoch 431/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.6450e-04 - acc: 1.0000 - val_loss: 0.5976 - val_acc: 0.7727\n",
      "Epoch 432/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.6370e-04 - acc: 1.0000 - val_loss: 0.5974 - val_acc: 0.7727\n",
      "Epoch 433/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.6285e-04 - acc: 1.0000 - val_loss: 0.5967 - val_acc: 0.7727\n",
      "Epoch 434/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.6198e-04 - acc: 1.0000 - val_loss: 0.5967 - val_acc: 0.7727\n",
      "Epoch 435/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.6117e-04 - acc: 1.0000 - val_loss: 0.5967 - val_acc: 0.7727\n",
      "Epoch 436/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.6046e-04 - acc: 1.0000 - val_loss: 0.5976 - val_acc: 0.7727\n",
      "Epoch 437/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.5961e-04 - acc: 1.0000 - val_loss: 0.5974 - val_acc: 0.7727\n",
      "Epoch 438/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.5886e-04 - acc: 1.0000 - val_loss: 0.5972 - val_acc: 0.7727\n",
      "Epoch 439/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.5812e-04 - acc: 1.0000 - val_loss: 0.5976 - val_acc: 0.7727\n",
      "Epoch 440/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.5722e-04 - acc: 1.0000 - val_loss: 0.5978 - val_acc: 0.7727\n",
      "Epoch 441/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.5653e-04 - acc: 1.0000 - val_loss: 0.5976 - val_acc: 0.7727\n",
      "Epoch 442/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.5571e-04 - acc: 1.0000 - val_loss: 0.5978 - val_acc: 0.7727\n",
      "Epoch 443/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.5496e-04 - acc: 1.0000 - val_loss: 0.5980 - val_acc: 0.7727\n",
      "Epoch 444/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.5417e-04 - acc: 1.0000 - val_loss: 0.5975 - val_acc: 0.7727\n",
      "Epoch 445/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.5340e-04 - acc: 1.0000 - val_loss: 0.5972 - val_acc: 0.7727\n",
      "Epoch 446/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.5273e-04 - acc: 1.0000 - val_loss: 0.5970 - val_acc: 0.7727\n",
      "Epoch 447/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.5196e-04 - acc: 1.0000 - val_loss: 0.5969 - val_acc: 0.7727\n",
      "Epoch 448/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.5113e-04 - acc: 1.0000 - val_loss: 0.5971 - val_acc: 0.7727\n",
      "Epoch 449/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.5040e-04 - acc: 1.0000 - val_loss: 0.5972 - val_acc: 0.7727\n",
      "Epoch 450/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.4972e-04 - acc: 1.0000 - val_loss: 0.5978 - val_acc: 0.7727\n",
      "Epoch 451/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.4900e-04 - acc: 1.0000 - val_loss: 0.5979 - val_acc: 0.7727\n",
      "Epoch 452/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.4827e-04 - acc: 1.0000 - val_loss: 0.5977 - val_acc: 0.7727\n",
      "Epoch 453/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.4751e-04 - acc: 1.0000 - val_loss: 0.5978 - val_acc: 0.7727\n",
      "Epoch 454/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.4681e-04 - acc: 1.0000 - val_loss: 0.5976 - val_acc: 0.7727\n",
      "Epoch 455/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.4617e-04 - acc: 1.0000 - val_loss: 0.5980 - val_acc: 0.7727\n",
      "Epoch 456/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.4539e-04 - acc: 1.0000 - val_loss: 0.5978 - val_acc: 0.7727\n",
      "Epoch 457/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.4472e-04 - acc: 1.0000 - val_loss: 0.5974 - val_acc: 0.7727\n",
      "Epoch 458/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.4400e-04 - acc: 1.0000 - val_loss: 0.5971 - val_acc: 0.7727\n",
      "Epoch 459/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.4336e-04 - acc: 1.0000 - val_loss: 0.5969 - val_acc: 0.7727\n",
      "Epoch 460/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.4267e-04 - acc: 1.0000 - val_loss: 0.5966 - val_acc: 0.7727\n",
      "Epoch 461/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.4193e-04 - acc: 1.0000 - val_loss: 0.5967 - val_acc: 0.7727\n",
      "Epoch 462/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.4138e-04 - acc: 1.0000 - val_loss: 0.5970 - val_acc: 0.7727\n",
      "Epoch 463/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.4069e-04 - acc: 1.0000 - val_loss: 0.5982 - val_acc: 0.7727\n",
      "Epoch 464/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.3995e-04 - acc: 1.0000 - val_loss: 0.5981 - val_acc: 0.7727\n",
      "Epoch 465/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.3937e-04 - acc: 1.0000 - val_loss: 0.5980 - val_acc: 0.7727\n",
      "Epoch 466/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.3867e-04 - acc: 1.0000 - val_loss: 0.5978 - val_acc: 0.7727\n",
      "Epoch 467/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.3806e-04 - acc: 1.0000 - val_loss: 0.5976 - val_acc: 0.7727\n",
      "Epoch 468/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.3737e-04 - acc: 1.0000 - val_loss: 0.5983 - val_acc: 0.7727\n",
      "Epoch 469/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.3672e-04 - acc: 1.0000 - val_loss: 0.5978 - val_acc: 0.7727\n",
      "Epoch 470/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.3612e-04 - acc: 1.0000 - val_loss: 0.5979 - val_acc: 0.7727\n",
      "Epoch 471/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.3554e-04 - acc: 1.0000 - val_loss: 0.5977 - val_acc: 0.7727\n",
      "Epoch 472/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.3484e-04 - acc: 1.0000 - val_loss: 0.5982 - val_acc: 0.7727\n",
      "Epoch 473/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.3420e-04 - acc: 1.0000 - val_loss: 0.5981 - val_acc: 0.7727\n",
      "Epoch 474/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.3360e-04 - acc: 1.0000 - val_loss: 0.5983 - val_acc: 0.7727\n",
      "Epoch 475/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.3297e-04 - acc: 1.0000 - val_loss: 0.5984 - val_acc: 0.7727\n",
      "Epoch 476/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.3239e-04 - acc: 1.0000 - val_loss: 0.5986 - val_acc: 0.7727\n",
      "Epoch 477/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.3173e-04 - acc: 1.0000 - val_loss: 0.5987 - val_acc: 0.7727\n",
      "Epoch 478/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121/121 [==============================] - 0s 1ms/step - loss: 1.3115e-04 - acc: 1.0000 - val_loss: 0.5986 - val_acc: 0.7727\n",
      "Epoch 479/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.3048e-04 - acc: 1.0000 - val_loss: 0.5987 - val_acc: 0.7727\n",
      "Epoch 480/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.2994e-04 - acc: 1.0000 - val_loss: 0.5986 - val_acc: 0.7727\n",
      "Epoch 481/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.2935e-04 - acc: 1.0000 - val_loss: 0.5984 - val_acc: 0.7727\n",
      "Epoch 482/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.2871e-04 - acc: 1.0000 - val_loss: 0.5989 - val_acc: 0.7727\n",
      "Epoch 483/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.2816e-04 - acc: 1.0000 - val_loss: 0.5987 - val_acc: 0.7727\n",
      "Epoch 484/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.2749e-04 - acc: 1.0000 - val_loss: 0.5986 - val_acc: 0.7727\n",
      "Epoch 485/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.2699e-04 - acc: 1.0000 - val_loss: 0.5981 - val_acc: 0.7727\n",
      "Epoch 486/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.2640e-04 - acc: 1.0000 - val_loss: 0.5983 - val_acc: 0.7727\n",
      "Epoch 487/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.2584e-04 - acc: 1.0000 - val_loss: 0.5986 - val_acc: 0.7727\n",
      "Epoch 488/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.2521e-04 - acc: 1.0000 - val_loss: 0.5985 - val_acc: 0.7727\n",
      "Epoch 489/500\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.2463e-04 - acc: 1.0000 - val_loss: 0.5984 - val_acc: 0.7727\n",
      "Epoch 490/500\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.2414e-04 - acc: 1.0000 - val_loss: 0.5980 - val_acc: 0.7727\n",
      "Epoch 491/500\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.2353e-04 - acc: 1.0000 - val_loss: 0.5985 - val_acc: 0.7727\n",
      "Epoch 492/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.2295e-04 - acc: 1.0000 - val_loss: 0.5986 - val_acc: 0.7727\n",
      "Epoch 493/500\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.2242e-04 - acc: 1.0000 - val_loss: 0.5984 - val_acc: 0.7727\n",
      "Epoch 494/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.2186e-04 - acc: 1.0000 - val_loss: 0.5985 - val_acc: 0.7727\n",
      "Epoch 495/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.2127e-04 - acc: 1.0000 - val_loss: 0.5987 - val_acc: 0.7727\n",
      "Epoch 496/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.2079e-04 - acc: 1.0000 - val_loss: 0.5987 - val_acc: 0.7727\n",
      "Epoch 497/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.2024e-04 - acc: 1.0000 - val_loss: 0.5986 - val_acc: 0.7727\n",
      "Epoch 498/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.1970e-04 - acc: 1.0000 - val_loss: 0.5981 - val_acc: 0.7727\n",
      "Epoch 499/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.1917e-04 - acc: 1.0000 - val_loss: 0.5986 - val_acc: 0.7727\n",
      "Epoch 500/500\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.1867e-04 - acc: 1.0000 - val_loss: 0.5979 - val_acc: 0.7727\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=500, verbose=1,validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 10, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[np.argmax(i) for i in model.predict(X_test)][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[np.argmax(i) for i in y_test][:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
